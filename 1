# -*- coding: utf-8 -*-
"""
author: batuhan
date  : 09-07-2021
"""

import DataProcessLibrary as dp
import ModelDevelopLibrary as mdl
import ModelSuccessLibrary as msl
import pandas as pd

data = pd.read_csv("../past_work/Veri_Setleri/volkswagen.csv")
#verisetini hangi tarihten itibaren incelemek istiyoruz
initial_date = "2014-01-01"

veriseti = dp.tarih_ayarlama(data, initial_date)
df = dp.volumeCheck(veriseti)
new_df = dp.obtainLabels(df)
new_df = dp.obtainPreviousLabel(new_df)
    


print(f"volumeCheck öncesi veri uzunluğu: {len(veriseti)}")
print(f"volumeCheck sonrası veri kaybolan veri {len(veriseti)-len(df)}")

#new_df.to_csv("model_data.csv", index = False)

model_data = new_df.copy()


df = mdl.minmaxScaler(model_data)

train, test = mdl.train_test_split(df,.95)

n_past = 50
n_future = 1

X_train, y_train, y_label_train = mdl.splitData(train, n_past, n_future)
X_test, y_test, y_label_test = mdl.splitData(test, n_past, n_future)

X_train, X_test = mdl.reshapeData_X(X_train, X_test)
y_train, y_test = mdl.reshapeData_y(y_train, y_test)
    
#import h5py
#from keras.models import load_model
#reconstructed_model = load_model("trainedModel.h5")

import os
os.environ['KMP_DUPLICATE_LIB_OK']='True'

#------------- MODEL DEVELOP ----------------#
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import LSTM
from keras.layers import Dropout

model = Sequential()
model.add(LSTM(units = n_past))
model.add(Dropout(.25))
model.add(Dense(1))
    
model.compile(optimizer='adagrad', loss = 'mean_squared_error')
model.fit(X_train, y_train, epochs = 5, batch_size=32)
model.summary()
y_predictions = model.predict(X_test)
msl.mseCalculator(y_predictions, y_test)
#
#model = Sequential()
#model.add(LSTM(units = n_past))
#model.add(Dropout(0.25))
#model.add(Dense(1))
#
#model.compile(optimizer='adam', loss = 'binary_crossentropy')
#model.fit(X_train, y_label_train, epochs = 5, batch_size=128)
#model.summary()
#
#y_predictions = model.predict(X_test)
#
#def yLabelPredictions(y_predictions):
#    from statistics import median
#    threshold = median(y_predictions)
#    y_label_predictions = list()
#    for prediction in y_predictions:
#        if prediction >= threshold:
#            y_label_predictions.append(1)
#        else:
#            y_label_predictions.append(-1)
#            
#    return y_label_predictions

#y_label_predictions = yLabelPredictions(y_predictions)

from sklearn.metrics import r2_score
print(' R2 degeri:',r2_score(y_test,y_predictions))


real_close = mdl.inverseScaler(model_data, y_test)
lstm_predictions = mdl.inverseScaler(model_data, y_predictions)

trend_lstm = msl.trendCalculator(y_predictions)
trend_real = msl.trendCalculator(y_test)

msl.metricsCalculator(trend_lstm, trend_real)

print(trend_lstm)
print(test[len(test)-13 :])

import PredictionGraphLibrary
PredictionGraphLibrary.printGraph(lstm_predictions, real_close)


#import pickle 
#importModel = pickle.load(open("monsterModel.kayit", 'rb'))
#
#monsterTahminler = importModel.predict(X_test)





